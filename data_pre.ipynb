{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdbd921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15469098",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = r\"C:\\Users\\Admin\\Desktop\\WHK ENDECODE\\traindata_npy\\inputs.npy\"\n",
    "out_path = r\"C:\\Users\\Admin\\Desktop\\WHK ENDECODE\\traindata_npy\\outputs.npy\"\n",
    "\n",
    "x = np.load(input_path).astype(np.float32)\n",
    "y = np.load(out_path).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d04bebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SolderJointDataset(Dataset):\n",
    "    def __init__(self, input_path, output_path, image_dir, transform=None):\n",
    "        # 读取输入和输出数据\n",
    "        self.x = np.load(input_path)     # (351, 3): T, A, YM\n",
    "        self.y = np.load(output_path)    # (351, 48): 特征向量\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # 读取所有图像文件名\n",
    "        self.image_files = os.listdir(image_dir)\n",
    "\n",
    "        # 做一个文件名索引，提升查找速度\n",
    "        self.filename_map = {self.construct_filename(*self.x[i]): i for i in range(len(self.x))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t, a, ym = self.x[idx]\n",
    "        features = self.y[idx]\n",
    "\n",
    "        filename = self.construct_filename(t, a, ym)\n",
    "        image_path = os.path.join(self.image_dir, filename)\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"图像文件不存在: {image_path}\")\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return {\n",
    "            \"input\": torch.tensor(features, dtype=torch.float32),     # shape: (48,)\n",
    "            \"condition\": torch.tensor([t, a, ym], dtype=torch.float32),  # shape: (3,)\n",
    "            \"image\": image  # shape: (3, H, W)\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def float_to_comma_str(val):\n",
    "        return f\"{val:.2f}\".replace('.', ',')\n",
    "\n",
    "    def construct_filename(self, t, a, ym):\n",
    "        t_str = self.float_to_comma_str(t)\n",
    "        a_str = f\"{a:.3f}\".replace('.', ',')\n",
    "        ym_str = self.float_to_comma_str(ym)\n",
    "        return f\"T{t_str} A{a_str} YM{ym_str}.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "813a5059",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = SolderJointDataset(\n",
    "    input_path=r\"C:\\Users\\Admin\\Desktop\\WHK ENDECODE\\traindata_npy\\inputs.npy\",\n",
    "    output_path=r\"C:\\Users\\Admin\\Desktop\\WHK ENDECODE\\traindata_npy\\outputs.npy\",\n",
    "    image_dir=r\"C:\\Users\\Admin\\Desktop\\WHK ENDECODE\\only image\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    input_vec = batch[\"input\"]        # (B, 48)\n",
    "    condition = batch[\"condition\"]    # (B, 3)\n",
    "    label_img = batch[\"image\"]        # (B, 3, H, W)\n",
    "    # 在这里你可以送入模型进行训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba3d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 获取一个 batch\n",
    "batch = next(iter(dataloader))\n",
    "\n",
    "input_vec = batch[\"input\"]        # (B, 48)\n",
    "condition = batch[\"condition\"]    # (B, 3)\n",
    "label_img = batch[\"image\"]        # (B, 3, 256, 256)\n",
    "\n",
    "# 打印 shape 和部分数值\n",
    "print(\"Input vector shape:\", input_vec.shape)\n",
    "print(\"Condition shape:\", condition.shape)\n",
    "print(\"Image shape:\", label_img.shape)\n",
    "\n",
    "print(\"Sample input vector:\", input_vec[0][:5])  # 前5个特征\n",
    "print(\"Sample condition:\", condition[0])         # T, A, YM\n",
    "\n",
    "# 可视化图像\n",
    "img_tensor = label_img[0]  # 取第一张\n",
    "img = F.to_pil_image(img_tensor)  # 转为 PIL 图像\n",
    "plt.imshow(img)\n",
    "plt.title(f\"T={condition[0][0]:.2f}, A={condition[0][1]:.3f}, YM={condition[0][2]:.2f}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c66003f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0: T-19,25 A0,200 YM20,00.png\n",
      "Sample 1: T-19,25 A0,200 YM23,50.png\n",
      "Sample 2: T-19,25 A0,200 YM27,00.png\n",
      "Sample 3: T-19,25 A0,290 YM20,00.png\n",
      "Sample 4: T-19,25 A0,290 YM23,50.png\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):  # 只看前5个\n",
    "    t, a, ym = dataset.x[i]\n",
    "    constructed_name = dataset.construct_filename(t, a, ym)\n",
    "    print(f\"Sample {i}: {constructed_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
